{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "* large margin classification : 마진이 가장 넓은 모델을 선택\n",
    "* support vector : 경계 최외곽에  위치한 샘플\n",
    "* 스케일에 민감\n",
    "    * 스케일이 서로 다르면 마진이 작아진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cm3 = ListedColormap(['#0000aa', '#ff2020', '#50ff50'])\n",
    "def plot_2d_classification(classifier, X, fill=False, ax=None, eps=None,\n",
    "                           alpha=1, cm=cm3):\n",
    "    # multiclass\n",
    "    if eps is None:\n",
    "        eps = X.std() / 2.\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - eps, X[:, 0].max() + eps\n",
    "    y_min, y_max = X[:, 1].min() - eps, X[:, 1].max() + eps\n",
    "    xx = np.linspace(x_min, x_max, 1000)\n",
    "    yy = np.linspace(y_min, y_max, 1000)\n",
    "\n",
    "    X1, X2 = np.meshgrid(xx, yy)\n",
    "    X_grid = np.c_[X1.ravel(), X2.ravel()]\n",
    "    decision_values = classifier.predict(X_grid)\n",
    "    ax.imshow(decision_values.reshape(X1.shape), extent=(x_min, x_max,\n",
    "                                                         y_min, y_max),\n",
    "              aspect='auto', origin='lower', alpha=alpha, cmap=cm)\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x = np.random.randint(0,125,(25,2))\n",
    "y = np.random.randint(126, 255,(25,2))\n",
    "trainData = np.vstack((x,y))\n",
    "trainData = np.float32(trainData)\n",
    "responses = np.zeros((50,1), np.int32)\n",
    "responses[0:25] = 1\n",
    "red = trainData[responses.ravel()==0]\n",
    "plt.scatter(red[:,0],red[:,1],80,'r','^')\n",
    "blue = trainData[responses.ravel()==1]\n",
    "plt.scatter(blue[:,0],blue[:,1],80,'b','s')\n",
    "\n",
    "newcomer = np.random.randint(0,255,(1,2)).astype(np.float32)\n",
    "plt.scatter(newcomer[:,0],newcomer[:,1],80,'g','o')\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(trainData, responses.ravel())\n",
    "\n",
    "#plot_2d_classification(svm, trainData)\n",
    "\n",
    "results = svm.predict(newcomer)\n",
    "plt.annotate('red' if results[0]==0.0 else 'blue', xy=newcomer[0],\n",
    "xytext=(newcomer[0]+1))\n",
    "print(\"result, 0=red, 1=blue: {}\\n\".format(results))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소프트 마진 분류\n",
    "* 샘플에 이상치가 있으면 일반화가 되지 않는다.\n",
    "* C 하이퍼파라미터로 조정\n",
    "    * 마진오류 : 서포트 벡터 넘어 경계 마진 안에 샘플이 위치하는 현상\n",
    "    * C 값이 작으면 마진 오류 커져(마진이 커짐), 일반화\n",
    "    * C 값이 크면 마진 오류 작아져(경계 마진이 작아짐), 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비선형 모델 다항식 추가\n",
    "* 비선형인 경우 특성을 2차식으로 추가 $x_2 = (x_1)^2$ 2차원 특성 생성\n",
    "* 다항식 특성 추가가 많아지면 연산이 복잡해져서 느려진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(10, dtype=np.float32)\n",
    "y = np.ones(10)\n",
    "\n",
    "x -= np.mean(x, axis=0)\n",
    "x /= np.std(x, axis=0)\n",
    "plt.plot(x,y, 'ob')\n",
    "plt.plot(x[3:7], y[3:7], 'sr')\n",
    "plt.title('non-liner model')\n",
    "plt.show()\n",
    "\n",
    "x2 = (x**2)\n",
    "plt.plot(x,x2, 'ob')\n",
    "plt.plot(x[3:7], x2[3:7], 'sr')\n",
    "plt.title('polynomial')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 커널 함수 트릭\n",
    "* 다항식 특성을 추가하지 않고 커널 함수로 새로운 거리 값을 계산\n",
    "    * 실제로 아무 특성도 추가하지 않으면서 다항식 특성을 많이 추가한 효과\n",
    "* 생성자에 kernel 함수 전달\n",
    "    * linear\n",
    "        * $K(x_i, x_j)= x_ix_j$\n",
    "        * `SVC(kernel='liner')`\n",
    "    * polynomial\n",
    "        * $K(x_i, x_j) = (\\gamma(x_i, x_j) + r)^d$, $d$ =degree\n",
    "            * $\\gamma$ =coef0 로 전달\n",
    "        * `SVC(kernel='ploy', degree=3, coef0=1, C=5)`\n",
    "            * degree : 다항식 차수\n",
    "            * coef0=0 : 다항식 커널의 상수항 $r$, 차수가 높아지면 1보다 크고 작은 값의 격차가 커짐, 고차항의 영향 조절\n",
    "    * rbf : (Gausian radial basis function)\n",
    "        * $K(x_i, x_j) = exp(\\gamma||x_i-x_j||^2)$\n",
    "            * $\\gamma$=gamma > 0, 작아 질수록 마진이 커진다.\n",
    "        * `SCV(kernel='rbf', gamma=5, C=0.001)`\n",
    "    * sigmoid : $K(x_i, x_j) = (tanh(\\gamma(x_i, x_j) + r))$, $r$은 coef0로 전달\n",
    "        * `SVC(kernel='sigmoid')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM 손글씨 인식 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "m = np.mean(X_train, axis=0)\n",
    "X_train -= m\n",
    "s = np.std(X_train, axis=0)\n",
    "X_train /= s\n",
    "print(m.shape, s.shape)\n",
    "\n",
    "X_test -=m\n",
    "X_test /= s\n",
    "\n",
    "svm = SVC(kernel='rbf',C=1000,  gamma=5)\n",
    "#svm = SVC(kernel='poly', degree=1, coef0=1, C=5, gamma=0.01)\n",
    "\n",
    "svm.fit(X_train,y_train)\n",
    "\n",
    "print(\"Train Accuracy :\", svm.score(X_train, y_train))\n",
    "print(\"Test Accuracy1 :\", svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import img2data\n",
    "\n",
    "image = cv2.imread('./img/0458.png')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "numbers = img2data.img2digits(image, (8,8))\n",
    "for i, n in enumerate(numbers):\n",
    "    pred = svm.predict(n/255*16)\n",
    "    plt.subplot(1, len(numbers), i+1)\n",
    "    plt.title(str(pred))\n",
    "    plt.imshow(n.reshape(8,8), cmap=\"gray\")\n",
    "    plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dl",
   "language": "python",
   "name": "ml_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
