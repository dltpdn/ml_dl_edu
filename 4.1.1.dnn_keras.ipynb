{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras 소개\n",
    "* keras.io\n",
    "* 동일한 코드로 CPU와 GPU 호환\n",
    "* 쉬운 API, 빠른 프로토타입핑 지원\n",
    "* CNN, RNN 지원 및 조합 가능\n",
    "* GAN, Neural Turing Machine 까지 어떤 딥러닝 모델에도 적합\n",
    "* MIT 라이센스, 상업적 자유\n",
    "* Python 2, 3 호환\n",
    "* 구글, 넷플릭스, 우버, 썬(CERN), 엘프, 스퀘어 등에서 활용\n",
    "* Kaggle에서도 인기\n",
    "\n",
    "###  케라스, 텐서플로, 씨아노, CNTK\n",
    "* 고수준 모델 라이브러리\n",
    "* 미분 따위 저수준 지원 안해\n",
    "    * 백엔드 엔진에게 위임\n",
    "        * 현재는 텐서플로, 씨아노, CNTK 3개만 지원, apache MXNet 추가 예정\n",
    "    * 코드 변경 없이 백엔드 교체 가능\n",
    "    * 텐서플로 기본 셋팅\n",
    "        * 텐서플로 텐서 연산 라이브러리\n",
    "            * CPU : Eigen(eigen.tuxfamily.org\n",
    "            * GPU : NVIDIA CUDA cuDNN(심층 신경망 라이브러리)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 구조\n",
    "* Neural Nework 생성 결정 요소\n",
    "    * 층(Layer) 갯수\n",
    "    * 입력 / 출력 갯수\n",
    "    * 손실함수 선택\n",
    "    * 옵티마이저 선택\n",
    "    \n",
    "### 층(Layer)\n",
    "* keras.layers 에 종류별 클래스\n",
    "    * 가장 일반적인 완전연결층(밀집층)\n",
    "        * Dense 클래스로 표현\n",
    "    * 시계열이나 시퀀스는 3D로 텐서로 표현\n",
    "        RNN, LSTM\n",
    "    * 이미지는 4D로 저장되고 CNN\n",
    "        * Conv2D 클래스\n",
    "* 생성할때 출력층은 필수고 입력 층은 input_shape 인자로 넘기는데, 샘플 축은 생략\n",
    "    * 예를 들어 `Dense(32, input_shape=(784,))` 이면 입력이 n x 784, 이때 n은 몇개든 상관없슴\n",
    "    * 만약 `Dense(10)` 이렇게 입력층 생략하면 앞 층의 출력의 갯수로 자동 지정\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Activation',\n",
       " 'ActivityRegularization',\n",
       " 'Add',\n",
       " 'AlphaDropout',\n",
       " 'AtrousConv1D',\n",
       " 'AtrousConv2D',\n",
       " 'AtrousConvolution1D',\n",
       " 'AtrousConvolution2D',\n",
       " 'Average',\n",
       " 'AveragePooling1D',\n",
       " 'AveragePooling2D',\n",
       " 'AveragePooling3D',\n",
       " 'AvgPool1D',\n",
       " 'AvgPool2D',\n",
       " 'AvgPool3D',\n",
       " 'BatchNormalization',\n",
       " 'Bidirectional',\n",
       " 'Concatenate',\n",
       " 'Conv1D',\n",
       " 'Conv2D',\n",
       " 'Conv2DTranspose',\n",
       " 'Conv3D',\n",
       " 'Conv3DTranspose',\n",
       " 'ConvLSTM2D',\n",
       " 'ConvLSTM2DCell',\n",
       " 'ConvRNN2D',\n",
       " 'ConvRecurrent2D',\n",
       " 'Convolution1D',\n",
       " 'Convolution2D',\n",
       " 'Convolution2DTranspose',\n",
       " 'Convolution3D',\n",
       " 'Cropping1D',\n",
       " 'Cropping2D',\n",
       " 'Cropping3D',\n",
       " 'CuDNNGRU',\n",
       " 'CuDNNLSTM',\n",
       " 'Deconv2D',\n",
       " 'Deconv3D',\n",
       " 'Deconvolution2D',\n",
       " 'Deconvolution3D',\n",
       " 'Dense',\n",
       " 'DepthwiseConv2D',\n",
       " 'Dot',\n",
       " 'Dropout',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'Flatten',\n",
       " 'GRU',\n",
       " 'GRUCell',\n",
       " 'GaussianDropout',\n",
       " 'GaussianNoise',\n",
       " 'GlobalAveragePooling1D',\n",
       " 'GlobalAveragePooling2D',\n",
       " 'GlobalAveragePooling3D',\n",
       " 'GlobalAvgPool1D',\n",
       " 'GlobalAvgPool2D',\n",
       " 'GlobalAvgPool3D',\n",
       " 'GlobalMaxPool1D',\n",
       " 'GlobalMaxPool2D',\n",
       " 'GlobalMaxPool3D',\n",
       " 'GlobalMaxPooling1D',\n",
       " 'GlobalMaxPooling2D',\n",
       " 'GlobalMaxPooling3D',\n",
       " 'Highway',\n",
       " 'Input',\n",
       " 'InputLayer',\n",
       " 'InputSpec',\n",
       " 'K',\n",
       " 'LSTM',\n",
       " 'LSTMCell',\n",
       " 'Lambda',\n",
       " 'Layer',\n",
       " 'LeakyReLU',\n",
       " 'LocallyConnected1D',\n",
       " 'LocallyConnected2D',\n",
       " 'Masking',\n",
       " 'MaxPool1D',\n",
       " 'MaxPool2D',\n",
       " 'MaxPool3D',\n",
       " 'MaxPooling1D',\n",
       " 'MaxPooling2D',\n",
       " 'MaxPooling3D',\n",
       " 'Maximum',\n",
       " 'MaxoutDense',\n",
       " 'Minimum',\n",
       " 'Multiply',\n",
       " 'PReLU',\n",
       " 'Permute',\n",
       " 'RNN',\n",
       " 'ReLU',\n",
       " 'Recurrent',\n",
       " 'RepeatVector',\n",
       " 'Reshape',\n",
       " 'SeparableConv1D',\n",
       " 'SeparableConv2D',\n",
       " 'SeparableConvolution1D',\n",
       " 'SeparableConvolution2D',\n",
       " 'SimpleRNN',\n",
       " 'SimpleRNNCell',\n",
       " 'Softmax',\n",
       " 'SpatialDropout1D',\n",
       " 'SpatialDropout2D',\n",
       " 'SpatialDropout3D',\n",
       " 'StackedRNNCells',\n",
       " 'Subtract',\n",
       " 'ThresholdedReLU',\n",
       " 'TimeDistributed',\n",
       " 'UpSampling1D',\n",
       " 'UpSampling2D',\n",
       " 'UpSampling3D',\n",
       " 'Wrapper',\n",
       " 'ZeroPadding1D',\n",
       " 'ZeroPadding2D',\n",
       " 'ZeroPadding3D',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'activations',\n",
       " 'add',\n",
       " 'advanced_activations',\n",
       " 'average',\n",
       " 'concatenate',\n",
       " 'constraints',\n",
       " 'conv_utils',\n",
       " 'convolutional',\n",
       " 'convolutional_recurrent',\n",
       " 'copy',\n",
       " 'core',\n",
       " 'cudnn_recurrent',\n",
       " 'deserialize',\n",
       " 'deserialize_keras_object',\n",
       " 'division',\n",
       " 'dot',\n",
       " 'embeddings',\n",
       " 'func_dump',\n",
       " 'func_load',\n",
       " 'has_arg',\n",
       " 'initializers',\n",
       " 'interfaces',\n",
       " 'local',\n",
       " 'maximum',\n",
       " 'merge',\n",
       " 'minimum',\n",
       " 'multiply',\n",
       " 'namedtuple',\n",
       " 'noise',\n",
       " 'normalization',\n",
       " 'np',\n",
       " 'object_list_uid',\n",
       " 'pooling',\n",
       " 'print_function',\n",
       " 'python_types',\n",
       " 'recurrent',\n",
       " 'regularizers',\n",
       " 'serialize',\n",
       " 'subtract',\n",
       " 'to_list',\n",
       " 'transpose_shape',\n",
       " 'warnings',\n",
       " 'wrappers']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "dir(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크(network)\n",
    "* 층을 어떻게 연결할지 결정하는 것\n",
    "* 나무로 치면 가지들의 모양\n",
    "* 가장 일반적인 것이 DAG(Directed Acyclic Graph, 비순환 유향 그래프: 일정한 방향이 있고 다시 돌아오는게 없는 그래프)\n",
    "* 가설공간을 결정하는 작업\n",
    "    * 아마도 Wx1 + Wx2 + .... Wxn을 얼마나 해야 하는지 결정\n",
    "* 어떤 모양을 만들어야 하는지 알아 내는건 과학보다 예술에 가깝다.\n",
    "\n",
    "### 손실함수와 옵티마이저\n",
    "* 주요 내용\n",
    "    * 손실함수 : 최소화 해야 할 값. 성공지표\n",
    "    * 옵티마이저 : 손실함수로 업데이트할 방법 결정, 역전파 알고리즘 구현한것,  SGD\n",
    "* 손실함수는 각층마다 있지만, 옵티마이저는 네트워크에 단 1개\n",
    "* 손실함수 잘못 선택하면 생기는 일\n",
    "    * 평균 인류 행복 지수 최대화 --> 불행한 사람 죽임\n",
    "* 손실함수 선택  지침\n",
    "    * 2개 클래스 : binary crossentropy\n",
    "    * 여러 클래스 분류 : categorical crossentropy\n",
    "    * 회귀 : 평균제곱오차(MSE)\n",
    "    * 시퀀스 : CTC(connection Temporal Classification)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화리뷰 분류 예제\n",
    "### IMDB 데이터셋\n",
    "* Dataset\n",
    "    * IMDB : Internet Movie DataBase\n",
    "    * train 25천개, test : 25천개\n",
    "    * 각각 긍정 부정 50%씩\n",
    "    * 리뷰 데이타는 단어를 숫자 시퀀스로 이미 변환\n",
    "    * 용량 17MB\n",
    "    * keras.datasets.imdb\n",
    "        * load_data(num_words=100000) : 빈도 높은 1만 단어만 사용\n",
    "        * data : 리뷰에 포함된 단어의 인덱스 값들, max:9999\n",
    "            * 각 샘플은 python list 타입, 길이가 제 각각이라서\n",
    "        * label : 0-부정, 1-긍정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련 세트와 검증(validation)셋트로 나눠서 fit()함수 호출 이때 `validation_data` 인자 사용\n",
    "    * `history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))`\n",
    "    * 이렇게 하면 `history` 디셔넉리가 'acc', 'loss', 'val_acc', 'val_loss' 4개의 키로 된 결과를 갖는다.\n",
    "        *  훈련 정확도와 손실, 검증 정확도와 손실 값이다.\n",
    "    * plot으로 각 에포크당 훈련결과와 검증 결과를 비교할 수 있다.\n",
    "        * ```\n",
    "        plt.plot(epochs, loss, 'bo', label='training loss')\n",
    "        plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
    "        ```\n",
    "    * 이걸 보면 어느 에폭에서 과대 적합이 시작되었는지 알 수 있다. 그 에폭과 전체 훈련 셋으로 다시 훈련 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
    "word_index = imdb.get_word_index()\n",
    "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 리뷰를 디코딩합니다. \n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터를 벡터로 변환합니다\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터를 벡터로 변환합니다\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 레이블을 벡터로 바꿉니다\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rainer/Dropbox/work/ml_dl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rainer/Dropbox/work/ml_dl/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 5s 337us/step - loss: 0.5084 - acc: 0.7813 - val_loss: 0.3797 - val_acc: 0.8685\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 3s 183us/step - loss: 0.3004 - acc: 0.9045 - val_loss: 0.3004 - val_acc: 0.8897\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 3s 181us/step - loss: 0.2179 - acc: 0.9286 - val_loss: 0.3085 - val_acc: 0.8712\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s 133us/step - loss: 0.1751 - acc: 0.9437 - val_loss: 0.2841 - val_acc: 0.8833\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 137us/step - loss: 0.1427 - acc: 0.9543 - val_loss: 0.2841 - val_acc: 0.8871\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 119us/step - loss: 0.1150 - acc: 0.9651 - val_loss: 0.3166 - val_acc: 0.8771\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 121us/step - loss: 0.0980 - acc: 0.9707 - val_loss: 0.3127 - val_acc: 0.8845\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0807 - acc: 0.9763 - val_loss: 0.3860 - val_acc: 0.8648\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0661 - acc: 0.9821 - val_loss: 0.3634 - val_acc: 0.8782\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0559 - acc: 0.9853 - val_loss: 0.3842 - val_acc: 0.8792\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0442 - acc: 0.9888 - val_loss: 0.4155 - val_acc: 0.8779\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0382 - acc: 0.9917 - val_loss: 0.4516 - val_acc: 0.8689\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0299 - acc: 0.9928 - val_loss: 0.4699 - val_acc: 0.8730\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0246 - acc: 0.9947 - val_loss: 0.5019 - val_acc: 0.8721\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0172 - acc: 0.9983 - val_loss: 0.5569 - val_acc: 0.8659\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0135 - acc: 0.9984 - val_loss: 0.5858 - val_acc: 0.8686\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0117 - acc: 0.9989 - val_loss: 0.6504 - val_acc: 0.8609\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0099 - acc: 0.9986 - val_loss: 0.6539 - val_acc: 0.8683\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0084 - acc: 0.9988 - val_loss: 0.6841 - val_acc: 0.8671\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0057 - acc: 0.9995 - val_loss: 0.7136 - val_acc: 0.8667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 0.4750 - acc: 0.8211\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 92us/step - loss: 0.2647 - acc: 0.9098\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 0.1984 - acc: 0.9305\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.1672 - acc: 0.9412\n",
      "25000/25000 [==============================] - 5s 202us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13381013],\n",
       "       [0.9996893 ],\n",
       "       [0.30844456],\n",
       "       ...,\n",
       "       [0.07031968],\n",
       "       [0.04384047],\n",
       "       [0.4529087 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 기사 분류 예제\n",
    "* 로이터의 뉴스 기사 데이타\n",
    "    * 46개 주제 클래스, 클래스당 최소 10개 새플\n",
    "    * keras.datasets.reuters.load_data(num_words=10000)\n",
    "    * 훈련셋 : 8,982, 테스트 셋 : 2,246 \n",
    "        *  기본값 0.2 비율\n",
    "        * 데이터 형식은 영화 리뷰와 같음.\n",
    "    * 다중 분류\n",
    "        * 마지막 층: softmax 사용\n",
    "            * activation='softmax'\n",
    "        * 손실함수 : 크로스엔트로피 \n",
    "            * loss='categorical_crossentropy'\n",
    "    * 검증데이타 1000개씩 떼서 앞에서 처럼 20 에폭 시도해\n",
    "        * 9번째 에폭에서 과적합 발견해서 그걸로 훈련 완료\n",
    "    * 예측\n",
    "        * prediction = model.prediction(x_test)\n",
    "        * 결과가 softmax라서 np.argmax(predictions) 사용\n",
    "            * 그러기 싫으면 에초에 레이블을 원핫 인코딩 하지 말고 정수 데이타 사용\n",
    "                * compile(loss='sparse_categorical_corssentropy')\n",
    "    * 중간 히든층이 적으면 잘안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 1us/step\n",
      "(8982,) (2246,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터 벡터 변환\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 레이블 벡터 변환\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# 테스트 레이블 벡터 변환\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 222us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.8697 - acc: 0.8165 - val_loss: 1.0793 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.7034 - acc: 0.8472 - val_loss: 0.9844 - val_acc: 0.7810\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.5667 - acc: 0.8802 - val_loss: 0.9411 - val_acc: 0.8040\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.4581 - acc: 0.9048 - val_loss: 0.9083 - val_acc: 0.8020\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 0.3695 - acc: 0.9231 - val_loss: 0.9363 - val_acc: 0.7890\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.3032 - acc: 0.9315 - val_loss: 0.8917 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.2537 - acc: 0.9414 - val_loss: 0.9071 - val_acc: 0.8110\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 138us/step - loss: 0.2187 - acc: 0.9471 - val_loss: 0.9178 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.1873 - acc: 0.9508 - val_loss: 0.9026 - val_acc: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.1703 - acc: 0.9521 - val_loss: 0.9322 - val_acc: 0.8100\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.1536 - acc: 0.9554 - val_loss: 0.9702 - val_acc: 0.8080\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.1390 - acc: 0.9559 - val_loss: 0.9678 - val_acc: 0.8150\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 0.1313 - acc: 0.9559 - val_loss: 1.0212 - val_acc: 0.8050\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 0.1219 - acc: 0.9579 - val_loss: 1.0250 - val_acc: 0.7980\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.1200 - acc: 0.9582 - val_loss: 1.0422 - val_acc: 0.8060\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.1138 - acc: 0.9594 - val_loss: 1.0969 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.1111 - acc: 0.9594 - val_loss: 1.0700 - val_acc: 0.8010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 2s 189us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 1.3712 - acc: 0.7121 - val_loss: 1.2758 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 1.0136 - acc: 0.7781 - val_loss: 1.1303 - val_acc: 0.7530\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 136us/step - loss: 0.7976 - acc: 0.8251 - val_loss: 1.0539 - val_acc: 0.7590\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.6393 - acc: 0.8624 - val_loss: 0.9754 - val_acc: 0.7920\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 0.5124 - acc: 0.8921 - val_loss: 0.9102 - val_acc: 0.8140\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 135us/step - loss: 0.4124 - acc: 0.9137 - val_loss: 0.8932 - val_acc: 0.8210\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.3355 - acc: 0.9290 - val_loss: 0.8732 - val_acc: 0.8260\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.2782 - acc: 0.9371 - val_loss: 0.9338 - val_acc: 0.8000\n",
      "2246/2246 [==============================] - 0s 139us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0224982713442876, 0.7756010686194165]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주택 가격 예측 예제\n",
    "* keras.datasets.boston_housing.load_data()\n",
    "* 훈련 404개, 테스트 102개 양이 너무 적어.\n",
    "    * 특성 :범죄율, 방개수, 고속도로 접근성 등 13가지\n",
    "* 레이블은 주택가격 천달러 단위\n",
    "* 숫자 단위가 제각각이니까 표준화 필요\n",
    "    * ```\n",
    "    mean = train_data.mean(axis=0)\n",
    "    train_data -= mean\n",
    "    std = train_data.std(axis=0)\n",
    "    train_data/=std\n",
    "    test_data -= mean\n",
    "    test_data /= std\n",
    "    ```\n",
    "    * 훈련데이타로 표준화 한 값으로 훈련 데이타도 적용\n",
    "        * 그렇지 안으면 의미가 달라짐\n",
    "* 회귀문제\n",
    "    * 마지막 층에 활성화 함수 사용 안함\n",
    "    * loss = 'mse', metrics=['mae']\n",
    "* 샘플수가 너무 적어서 k-fold 적용 필요\n",
    "    * 같은 데이타로 돌아가며 역할 바꿔서 여러번 훈련하고 평가한걸 누적 후 평균\n",
    "    * 1차 :검증, 훈련, 훈련\n",
    "    * 2차: 훈련, 검증, 훈련\n",
    "    * 3차 : 훈련, 훈련, 검증\n",
    "    * 각 폴드에서 검증 점수 로그에 저장\n",
    "        * mae_history = history.history['val_mean_absolute_error']\n",
    "        * all.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 7us/step\n",
      "(404, 13) (102, 13)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # 동일한 모델을 여러 번 생성할 것이므로 함수를 만들어 사용합니다\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드 # 0\n",
      "처리중인 폴드 # 1\n",
      "처리중인 폴드 # 2\n",
      "처리중인 폴드 # 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('처리중인 폴드 #', i)\n",
    "    # 검증 데이터 준비: k번째 분할\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # 훈련 데이터 준비: 다른 분할 전체\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # 케라스 모델 구성(컴파일 포함)\n",
    "    model = build_model()\n",
    "    # 모델 훈련(verbose=0 이므로 훈련 과정이 출력되지 않습니다)\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    # 검증 세트로 모델 평가\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(all_scores)\n",
    "print(np.mean(all_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# 메모리 해제\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드 # 0\n",
      "처리중인 폴드 # 1\n",
      "처리중인 폴드 # 2\n",
      "처리중인 폴드 # 3\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('처리중인 폴드 #', i)\n",
    "    # 검증 데이터 준비: k번째 분할\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # 훈련 데이터 준비: 다른 분할 전체\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # 케라스 모델 구성(컴파일 포함)\n",
    "    model = build_model()\n",
    "    # 모델 훈련(verbose=0 이므로 훈련 과정이 출력되지 않습니다)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    mae_history = history.history['val_mean_absolute_error']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_mae_histories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5e95c09630fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m average_mae_history = [\n\u001b[0;32m----> 2\u001b[0;31m     np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-5e95c09630fc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m average_mae_history = [\n\u001b[0;32m----> 2\u001b[0;31m     np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_mae_histories' is not defined"
     ]
    }
   ],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 새롭게 컴파인된 모델을 얻습니다\n",
    "model = build_model()\n",
    "# 전체 데이터로 훈련시킵니다\n",
    "model.fit(train_data, train_targets,\n",
    "          epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_dl",
   "language": "python",
   "name": "ml_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
