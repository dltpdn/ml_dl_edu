{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2 RNN:Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "* Recurrent Neural Network, 순환 신경망\n",
    "* 과거의 행위가 다음 판단에 영향을 미치는 경우\n",
    "* 고정 데이터가 아닌 순서가 있는 데이터\n",
    "    * 예) 안녕, 넌 이름이 뭐니? Vs 안녕, 그 동안 즐거웠어.\n",
    "* 구글 번역 서비스\n",
    "    * Seq2Seq 신경망 모델\n",
    "![image.png](https://i.imgur.com/Ot9qXuc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순환 신경망\n",
    "* 시퀀스 데이터 처리할 수 있는 방법\n",
    "    * RNN\n",
    "    * 1D Convnet\n",
    "* 주요 사례\n",
    "    * 문서 분류, 시계열 분류\n",
    "    * 감성분석\n",
    "* 특징\n",
    "    * 이전 상태 유지\n",
    "    ```python\n",
    "    state = 0\n",
    "    for input in inputs:\n",
    "        outout, state = rnn_cell(input, state)\n",
    "    ```\n",
    "*  RNN 구조 유형\n",
    "![image.png](https://i.imgur.com/MAesSJV.png)\n",
    "* RNN 개선\n",
    "    * LSTM(Long Short Term Memory)\n",
    "    * GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN\n",
    "* 상태는 한개의 히든 벡터 H 로 구성\n",
    "* $h_t = fw(h_{t-1}, x_t)$\n",
    "    * $h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t + b_h)$\n",
    "    * $ y_t = W_{hy}h_t + b_y $\n",
    "![image.png](https://i.imgur.com/Q1xfRVJ.png)\n",
    "* 학습할 변수들\n",
    "    * $W_{hx}$, $W_{hh}$, $b_h$\n",
    "    * $W_{hy}$, $b_y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla RNN Graph\n",
    "![image.png](https://i.imgur.com/Szpv2aU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanila RNN 실습\n",
    "* RNN 구조를 직접 만들어 다음 글자 예측 실습\n",
    "    * 입력 : \"hihell\"\n",
    "    * 출력 : \"ihello\"\n",
    "    * many to many\n",
    "![image.png](https://i.imgur.com/F8toAhT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입출력 데이타 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sentence = \"hihello\"\n",
    "x = \"hihell\"\n",
    "y = \"ihello\"\n",
    "\n",
    "voca = list({c for c in sentence})\n",
    "dic = {c:i for i,c in enumerate(voca)}\n",
    "dic2idx = {i:c for i, c in enumerate(voca)}\n",
    "print(dic, dic2idx)\n",
    "\n",
    "n_class = len(dic)  #example size\n",
    "n_time_steps = len(x) #sequence\n",
    "hidden_size = n_class #output size\n",
    "\n",
    "x_idx = [dic[c] for c in x]\n",
    "print(\"x_idx:\", x_idx)\n",
    "y_idx = [dic[c] for c in y]\n",
    "print(\"y_idx:\", y_idx)\n",
    "\n",
    "x_enc =tf.keras.utils.to_categorical(x_idx, num_classes=n_class)\n",
    "x_enc = np.expand_dims(x_enc, axis=0)\n",
    "print(\"x_enc:\", x_enc, x_enc.shape, )\n",
    "\n",
    "y_enc = tf.keras.utils.to_categorical(y_idx, num_classes=n_class)\n",
    "y_enc = np.expand_dims(y_enc, axis=0)\n",
    "print(\"y_enc:\", y_enc, y_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden state 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "initializer =  tf.keras.initializers.GlorotUniform() #xavier\n",
    "\n",
    "Wx = tf.Variable(initializer([n_class, hidden_size]), name=\"Wx\" )\n",
    "Wh = tf.Variable(initializer([hidden_size, hidden_size]), name=\"Wh\" )\n",
    "bh = tf.Variable(initializer([hidden_size]), name=\"bias_h\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden state 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_step(previous_hidden_state, x):\n",
    "    current_hidden_state = tf.tanh(\n",
    "        tf.matmul(previous_hidden_state, Wh) + \n",
    "        tf.matmul(x, Wx) + bh)\n",
    "    return current_hidden_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 출력 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wy = tf.Variable(initializer([hidden_size, n_class]))\n",
    "by = tf.Variable(initializer([n_class]))\n",
    "\n",
    "def get_linear_layer(hidden_state):\n",
    "    return tf.matmul(hidden_state, Wy) + by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `tf.scan(fn, elemes)`\n",
    "    * 모든 elemes를 순회하면서 fn에 전달\n",
    "    * 이전 fn의 반환 값과 elemens의 다음 항목을 fn에 전달\n",
    "    * 모든 fn의 반환 값을 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.scan() 사용 설명을 위한 예시\n",
    "def f(prev, next):\n",
    "    print(prev, next)\n",
    "    return prev + next\n",
    "\n",
    "data = np.arange(5).reshape(-1,1)+1\n",
    "ret = tf.scan(f, data)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "n_epoch = 500\n",
    "for step in range(n_epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        X_ = tf.transpose(x_enc, perm=[1, 0, 2])\n",
    "        all_hidden_states = tf.scan(rnn_step, X_, name='states')#, initializer=init_hidden)\n",
    "        all_outputs = tf.map_fn(get_linear_layer, all_hidden_states)\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_outputs, labels=y_enc))\n",
    "    grads = tape.gradient(cost, [Wy, by, Wx, Wh,  bh])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [Wy, by, Wx, Wh,  bh]))\n",
    "    if (step+1) % 20 == 0:\n",
    "            if step+ 1== n_epoch :\n",
    "                print(all_outputs)\n",
    "            prediction = tf.argmax(all_outputs, axis=2)\n",
    "            print(\"step:{}, cost:{}, predict:{}, str:{}\".format(step, cost, np.squeeze(prediction), [dic2idx[i] for i in np.squeeze(prediction)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF RNN API\n",
    "* `cell = tf.keras.layers..rnn_cell.SimpleRNNCell(units=hidden_size)`\n",
    "    * RNN 구현을 위해 필요한 변수 선언 및 구조 제공\n",
    "    * `hidden_size` : output, state size\n",
    "* `rnn = tf.keras.layers.RNN(cell,return_sequences=True, return_state=True)`\n",
    "* `outputs, states = rnn(X)`\n",
    "    * rnn_cell을 전달 받아 반복(tf.scan()) 연산해서 output과 state 계산\n",
    "    * rnn.trainable_variables : 학습할 변수 얻기\n",
    "* `rnn = tf.keras.layers..rnn_cell.SimpleRNNCell(units=hidden_size, return_sequences=True, return_state=True)`\n",
    "    * SimpleRNNCell + RNN\n",
    "    * Cell과 RNN 역할을 동시에 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_data = np.array([[[1,2,3,4],\n",
    "                    [5,6,7,8]]], dtype=np.float32) #(1,2,4) : (batch, time_step, depth)\n",
    "print(x_data.shape)\n",
    "\n",
    "hidden_size = 2\n",
    "cell = tf.keras.layers.SimpleRNNCell(hidden_size)\n",
    "\n",
    "print(cell.output_size, cell.state_size)\n",
    "rnn = tf.keras.layers.RNN(cell, return_sequences=True, return_state=True)\n",
    "outputs, return_state = rnn(x_data)\n",
    "print(outputs, return_state)\n",
    "print(rnn.trainable_variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF RNN API로 \"hi hello\" 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sentence = \"hihello\"\n",
    "x = \"hihell\"\n",
    "y = \"ihello\"\n",
    "\n",
    "voca = list({c for c in sentence})\n",
    "dic = {c:i for i,c in enumerate(voca)}\n",
    "dic2idx = {i:c for i, c in enumerate(voca)}\n",
    "print(dic, dic2idx)\n",
    "\n",
    "n_class = len(dic)  #example size\n",
    "n_time_steps = len(x) #sequence\n",
    "hidden_size = n_class #output size\n",
    "\n",
    "x_idx = [dic[c] for c in x]\n",
    "print(\"x_idx:\", x_idx)\n",
    "y_idx = [dic[c] for c in y]\n",
    "print(\"y_idx:\", y_idx)\n",
    "\n",
    "x_enc =tf.keras.utils.to_categorical(x_idx, num_classes=n_class)\n",
    "x_enc = np.expand_dims(x_enc, axis=0)\n",
    "print(\"x_enc:\", x_enc, x_enc.shape, )\n",
    "\n",
    "y_enc = tf.keras.utils.to_categorical(y_idx, num_classes=n_class)\n",
    "y_enc = np.expand_dims(y_enc, axis=0)\n",
    "print(\"y_enc:\", y_enc, y_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initializer =  tf.initializers.GlorotUniform() #xavier\n",
    "Wy = tf.Variable(initializer([hidden_size, n_class]))\n",
    "by = tf.Variable(initializer([n_class]))\n",
    "\n",
    "def get_linear_layer(hidden_state):\n",
    "    return tf.matmul(hidden_state, Wy) + by\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "#cell = tf.keras.layers.SimpleRNNCell(hidden_size)\n",
    "#rnn = tf.keras.layers.RNN(cell, return_sequences=True, return_state=True)\n",
    "rnn = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, return_state=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "n_epoch = 500\n",
    "for step in range(n_epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs, states = rnn(x_enc)\n",
    "        all_outputs = tf.map_fn(get_linear_layer, outputs)\n",
    "        variables = rnn.trainable_variables + [Wy, by]\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_outputs, labels=y_enc))\n",
    "    grads = tape.gradient(cost, variables)\n",
    "    optimizer.apply_gradients(zip(grads, variables))\n",
    "    if (step+1) % 20 == 0:\n",
    "        prediction = tf.argmax(all_outputs, axis=2)\n",
    "        print(\"step:{}, cost:{}, predict:{}, str:{}\".format(step, cost, np.squeeze(prediction), [dic2idx[i] for i in np.squeeze(prediction)]))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "* Long Short-Term Memory Unit\n",
    "* Hochreiter(1997) 제안, RNN 변형 \n",
    "* 자연어 처리 분야 딥러닝 기법 중 가장 활발히 사용\n",
    "* RNN의 맨 뒤에서 맨 앞의 정보를 기억하지 못하는 특성 보완\n",
    "* RNN의 Hidden state에 cell-state를 추가\n",
    "* 오차의 그라디언트가 시간을 거슬러 잘 흘러갈 수 있다.\n",
    "* 1000단계가 넘는 Backpropagation 과정에서 오차 값 유지\n",
    "![image.png](https://i.imgur.com/POpVFUa.png)\n",
    "\n",
    "* Hidden Layer를 4개의 계층으로 구성\n",
    "    * Cell State : 이전 정보를 다음 단계로 전달, 3가지 게이트에 의해 전달 여부 결정\n",
    "    * Forget Gate : 기존 Cell State에서 어떠한 정보를 지울 지 결정\n",
    "    * Input Gate : Cell State에 저장할 새로운 정보를 결정\n",
    "    * Output Gate : Cell State 값을 다음 상태로 출력할 지 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRUCell\n",
    "* Gated Recurrent Units\n",
    "* 2014 뉴욕대 조경현 교수 제안\n",
    "* LSTM의 변형, 더 간단한 구조\n",
    "* 게이트 된 순환 유닛(Gate Recurrent Unit)\n",
    "* 잊기와 입력 게이트들을 하나의 단일 Update 게이트로 통합\n",
    "* 셀 상태와 숨겨진 상태 통합\n",
    "![image.png](https://i.imgur.com/c2YyJz9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM/GRU를 이용한 \"hihello\" 실습\n",
    "* `tf.keras.layers.LSTMCell()`\n",
    "* `tf.keras.layers.LSTM()`\n",
    "* `tf.keras.layers.GRUCell()`\n",
    "* `tf.keras.layers.GRU()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sentence = \"hihello\"\n",
    "x = \"hihell\"\n",
    "y = \"ihello\"\n",
    "\n",
    "voca = list({c for c in sentence})\n",
    "dic = {c:i for i,c in enumerate(voca)}\n",
    "dic2idx = {i:c for i, c in enumerate(voca)}\n",
    "print(dic, dic2idx)\n",
    "\n",
    "n_class = len(dic)  #example size\n",
    "n_time_steps = len(x) #sequence\n",
    "hidden_size = n_class #output size\n",
    "\n",
    "x_idx = [dic[c] for c in x]\n",
    "print(\"x_idx:\", x_idx)\n",
    "y_idx = [dic[c] for c in y]\n",
    "print(\"y_idx:\", y_idx)\n",
    "\n",
    "x_enc =tf.keras.utils.to_categorical(x_idx, num_classes=n_class)\n",
    "x_enc = np.expand_dims(x_enc, axis=0)\n",
    "print(\"x_enc:\", x_enc, x_enc.shape, )\n",
    "\n",
    "y_enc = tf.keras.utils.to_categorical(y_idx, num_classes=n_class)\n",
    "y_enc = np.expand_dims(y_enc, axis=0)\n",
    "print(\"y_enc:\", y_enc, y_enc.shape)\n",
    "\n",
    "\n",
    "############# Cell Selecte ##############################\n",
    "#cell = tf.keras.layers.LSTMCell(hidden_size)\n",
    "cell = tf.keras.layers.GRUCell(hidden_size)\n",
    "#rnn = tf.keras.layers.RNN(cell, return_sequences=True)\n",
    "#rnn = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "rnn = tf.keras.layers.GRU(hidden_size, return_sequences=True)\n",
    "\n",
    "initializer =  tf.initializers.GlorotUniform() #xavier\n",
    "Wy = tf.Variable(initializer([hidden_size, n_class]))\n",
    "by = tf.Variable(initializer([n_class]))\n",
    "\n",
    "def get_linear_layer(hidden_state):\n",
    "    return tf.matmul(hidden_state, Wy) + by\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "prediction = tf.argmax(all_outputs, axis=2)\n",
    "\n",
    "n_epoch = 1000\n",
    "for step in range(n_epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = rnn(x_enc)\n",
    "        all_outputs = tf.map_fn(get_linear_layer, outputs)\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=all_outputs, labels=y_enc))\n",
    "    grads = tape.gradient(cost, rnn.trainable_variables + [Wy, by])\n",
    "    optimizer.apply_gradients(zip(grads, rnn.trainable_variables + [Wy, by]))\n",
    "    if (step+1) % 20 == 0:\n",
    "        prediction = tf.argmax(all_outputs, axis=2)\n",
    "        print(\"step:{}, cost:{}, predict:{}, str:{}\".format(step, cost, np.squeeze(prediction), [dic2idx[i] for i in np.squeeze(prediction)]))                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Model을 사용한 \"hihello\" 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sentence = \"hihello\"\n",
    "x = \"hihell\"\n",
    "y = \"ihello\"\n",
    "\n",
    "voca = list({c for c in sentence})\n",
    "dic = {c:i for i,c in enumerate(voca)}\n",
    "dic2idx = {i:c for i, c in enumerate(voca)}\n",
    "print(dic, dic2idx)\n",
    "\n",
    "n_class = len(dic)  #example size\n",
    "n_time_steps = len(x) #sequence\n",
    "hidden_size = n_class #output size\n",
    "\n",
    "x_idx = [dic[c] for c in x]\n",
    "print(\"x_idx:\", x_idx)\n",
    "y_idx = [dic[c] for c in y]\n",
    "print(\"y_idx:\", y_idx)\n",
    "\n",
    "x_enc =tf.keras.utils.to_categorical(x_idx, num_classes=n_class)\n",
    "x_enc = np.expand_dims(x_enc, axis=0)\n",
    "print(\"x_enc:\", x_enc, x_enc.shape, )\n",
    "\n",
    "y_enc = tf.keras.utils.to_categorical(y_idx, num_classes=n_class)\n",
    "y_enc = np.expand_dims(y_enc, axis=0)\n",
    "print(\"y_enc:\", y_enc, y_enc.shape)\n",
    "\n",
    "\n",
    "############# model build ##############################\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.LSTM(hidden_size, input_shape=(n_time_steps, n_class), return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(hidden_size, input_shape=(n_time_steps, n_class), return_sequences=True))\n",
    "model.add(tf.keras.layers.Dense(hidden_size))\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "n_epoch = 1000\n",
    "for step in range(n_epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(x_enc)\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=y_enc))\n",
    "    grads = tape.gradient(cost, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    if (step+1) % 20 == 0:\n",
    "        prediction = tf.argmax(model(x_enc), axis=2)\n",
    "        print(\"step:{}, cost:{}, predict:{}, str:{}\".format(step, cost, np.squeeze(prediction), [dic2idx[i] for i in np.squeeze(prediction)]))                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras API 사용 'hihello' 예제 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "keras = tf.keras\n",
    "\n",
    "sentence = \"hihello\"\n",
    "x = \"hihell\"\n",
    "y = \"ihello\"\n",
    "\n",
    "voca = list({c for c in sentence})\n",
    "dic = {c:i for i,c in enumerate(voca)}\n",
    "print(dic)\n",
    "\n",
    "n_class = len(dic)  #example size\n",
    "n_time_steps = len(x) #sequence\n",
    "hidden_size = n_class #output size\n",
    "\n",
    "x_idx = [dic[c] for c in x]\n",
    "print(\"x_idx:\", x_idx)\n",
    "y_idx = [dic[c] for c in y]\n",
    "print(\"y_idx:\", y_idx)\n",
    "\n",
    "x_enc =tf.keras.utils.to_categorical(x_idx, num_classes=n_class)\n",
    "x_enc = np.expand_dims(x_enc, axis=0)\n",
    "print(\"x_enc:\", x_enc, x_enc.shape, )\n",
    "\n",
    "y_enc = tf.keras.utils.to_categorical(y_idx, num_classes=n_class)\n",
    "y_enc = np.expand_dims(y_enc, axis=0)\n",
    "print(\"y_enc:\", y_enc, y_enc.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM((hidden_size), input_shape=(n_time_steps, n_class), return_sequences=True))\n",
    "model.add(keras.layers.Dense(hidden_size))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "n_epochs = 500\n",
    "model.fit(x_enc, np.reshape(y_idx, (1,6,1)), epochs=n_epochs, verbose=0)\n",
    "\n",
    "preds = model.predict(x_enc, verbose=0)\n",
    "print(preds, np.squeeze(np.argmax(preds, axis=2)))\n",
    "print([voca[i] for i in np.squeeze(np.argmax(preds, axis=2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 이미지\n",
    "* many to one\n",
    "* 28 * 28 숫자 이미지 : 시퀀스로서의 이미지\n",
    "![image.png](https://i.imgur.com/1dwjGgP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "element_size = 28\n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# MNIST 데이터 불러오기 위한 함수 정의\n",
    "def mnist_load():\n",
    "    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "    # Train set\n",
    "    train_x = train_x.astype('float32') / 255.\n",
    "    # Test set\n",
    "    test_x = test_x.astype('float32') / 255.\n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "# MNIST 데이터 불러오기\n",
    "(train_x, train_y), (test_x, test_y) = mnist_load()\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM((hidden_layer_size), input_shape=(time_steps, element_size)))\n",
    "model.add(keras.layers.Dense(num_classes))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(train_x, train_y, epochs=20, batch_size=batch_size)\n",
    "\n",
    "results = model.evaluate(test_x, test_y,  verbose=0)\n",
    "print(f\"Test loss:{results[0]}, accuracy:{results[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석기\n",
    "#### konlpy 설치\n",
    "* https://konlpy-ko.readthedocs.io/ko/latest/\n",
    "* 설치 절차\n",
    "    1. JDK 설치 및 JAVA_HOME 설정\n",
    "        * https://www.oracle.com/technetwork/java/javase/downloads/index.html\n",
    "        * JAVA_HOME 환경 변수 설정\n",
    "    2. JPype 다운로드 및 설치\n",
    "        * Download : https://www.lfd.uci.edu/~gohlke/pythonlibs/#jpype\n",
    "            * 사용하는 파이썬 버전에 맞게 골라서 다운도르\n",
    "        * 설치 : `pip install JPype-XXX.whl`\n",
    "    3. Konlpy 설치 \n",
    "        * `!pip install konlpy`\n",
    "    * 맥 : \n",
    "        * `export MACOSX_DEPLOYMENT_TARGET=10.10`\n",
    "        * `CFLAGS=\"-stdlib=libc++\" pip install konlpy`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install ./assets/JPype1‑0.7.1‑cp37‑cp37m‑win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.4 (v3.6.4:d48ecebad5, Dec 18 2017, 21:07:28) \\n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Using cached https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.6 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from konlpy) (1.16.6)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from konlpy) (3.8.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from konlpy) (4.6.0)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/62/0f312d578e0165e9b5e8fcae0291f7ee83783b3805f59071006b21229d55/JPype1-0.7.1.tar.gz\n",
      "Collecting lxml>=4.1.0 (from konlpy)\n",
      "  Using cached https://files.pythonhosted.org/packages/d0/70/a067810a5b6ddfea32600bfbbd9916dae4d4b5b0754d49c50208c7d00663/lxml-4.4.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting colorama (from konlpy)\n",
      "  Using cached https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.11.1 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tweepy>=3.7.0->konlpy) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tweepy>=3.7.0->konlpy) (1.13.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2017.7.27.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Building wheels for collected packages: JPype1\n",
      "  Running setup.py bdist_wheel for JPype1 ... \u001b[?25lerror\n",
      "  Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-0yF2IQ/JPype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-wheel-lWiBJa --python-tag cp27:\n",
      "  /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'use_scm_version'\n",
      "    warnings.warn(msg)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.6-intel-2.7\n",
      "  creating build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcollection.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcomparable.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_classpath.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jtypes.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_pykeywords.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jproxy.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_gui.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_darwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/nio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jstring.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_cygwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/__init__.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jboxed.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/types.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/beans.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jvmfinder.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/imports.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcustomizer.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_core.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jinit.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_linux.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jarray.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jobject.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/pickle.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jclass.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_windows.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jexception.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/reflect.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jpackage.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  running build_ext\n",
      "  running build_java\n",
      "  Using Jar cache\n",
      "  creating build/lib\n",
      "  creating build/lib/org\n",
      "  creating build/lib/org/jpype\n",
      "  creating build/lib/org/jpype/classloader\n",
      "  copying native/jars/org/jpype/classloader/JPypeClassLoader.class -> build/lib/org/jpype/classloader\n",
      "  copying native/jars/org.jpype.jar -> build/lib\n",
      "  running build_thunk\n",
      "  Building thunks\n",
      "    including thunk build/lib/org/jpype/classloader/JPypeClassLoader.class\n",
      "    including thunk build/lib/org.jpype.jar\n",
      "  setupext/build_ext.py:87: FeatureNotice: Turned ON Numpy support for fast Java array access\n",
      "    FeatureNotice)\n",
      "  building '_jpype' extension\n",
      "  creating build/temp.macosx-10.6-intel-2.7\n",
      "  creating build/temp.macosx-10.6-intel-2.7/build\n",
      "  creating build/temp.macosx-10.6-intel-2.7/build/src\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native/python\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native/common\n",
      "  /usr/bin/clang -fno-strict-aliasing -fno-common -dynamic -arch i386 -arch x86_64 -g -DNDEBUG -g -fwrapv -O3 -Wall -DMACOSX=1 -DHAVE_NUMPY=1 -Inative/common/include -Inative/python/include -Ibuild/src -Inative/jni_include -I/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/include -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c build/src/jp_thunk.cpp -o build/temp.macosx-10.6-intel-2.7/build/src/jp_thunk.o -ggdb\n",
      "  warning: include path for stdlibc++ headers not found; pass '-std=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "  In file included from build/src/jp_thunk.cpp:1:\n",
      "  In file included from build/src/jp_thunk.h:3:\n",
      "  native/common/include/jpype.h:82:10: fatal error: 'map' file not found\n",
      "  #include <map>\n",
      "           ^~~~~\n",
      "  1 warning and 1 error generated.\n",
      "  error: command '/usr/bin/clang' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for JPype1\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for JPype1\n",
      "Failed to build JPype1\n",
      "\u001b[31mmarkdown 3.1.1 has requirement setuptools>=36, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorboard 2.1.0 has requirement setuptools>=41.0.0, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-auth 1.10.0 has requirement setuptools>=40.3.0, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: JPype1, lxml, colorama, konlpy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py install for JPype1 ... \u001b[?25lerror\n",
      "    Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-0yF2IQ/JPype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-record-7VS2Jl/install-record.txt --single-version-externally-managed --compile:\n",
      "    /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'use_scm_version'\n",
      "      warnings.warn(msg)\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build/lib.macosx-10.6-intel-2.7\n",
      "    creating build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcollection.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcomparable.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_classpath.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jtypes.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_pykeywords.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jproxy.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_gui.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_darwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/nio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jstring.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_cygwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/__init__.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jboxed.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/types.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/beans.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jvmfinder.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/imports.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcustomizer.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_core.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jinit.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_linux.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jarray.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jobject.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/pickle.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jclass.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_windows.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jexception.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/reflect.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jpackage.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    running build_ext\n",
      "    running build_java\n",
      "    Using Jar cache\n",
      "    copying native/jars/org/jpype/classloader/JPypeClassLoader.class -> build/lib/org/jpype/classloader\n",
      "    copying native/jars/org.jpype.jar -> build/lib\n",
      "    running build_thunk\n",
      "    Building thunks\n",
      "      including thunk build/lib/org/jpype/classloader/JPypeClassLoader.class\n",
      "      including thunk build/lib/org.jpype.jar\n",
      "    setupext/build_ext.py:87: FeatureNotice: Turned ON Numpy support for fast Java array access\n",
      "      FeatureNotice)\n",
      "    building '_jpype' extension\n",
      "    creating build/temp.macosx-10.6-intel-2.7\n",
      "    creating build/temp.macosx-10.6-intel-2.7/build\n",
      "    creating build/temp.macosx-10.6-intel-2.7/build/src\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native/python\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native/common\n",
      "    /usr/bin/clang -fno-strict-aliasing -fno-common -dynamic -arch i386 -arch x86_64 -g -DNDEBUG -g -fwrapv -O3 -Wall -DMACOSX=1 -DHAVE_NUMPY=1 -Inative/common/include -Inative/python/include -Ibuild/src -Inative/jni_include -I/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/include -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c build/src/jp_thunk.cpp -o build/temp.macosx-10.6-intel-2.7/build/src/jp_thunk.o -ggdb\n",
      "    warning: include path for stdlibc++ headers not found; pass '-std=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "    In file included from build/src/jp_thunk.cpp:1:\n",
      "    In file included from build/src/jp_thunk.h:3:\n",
      "    native/common/include/jpype.h:82:10: fatal error: 'map' file not found\n",
      "    #include <map>\n",
      "             ^~~~~\n",
      "    1 warning and 1 error generated.\n",
      "    error: command '/usr/bin/clang' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-0yF2IQ/JPype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-record-7VS2Jl/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-0yF2IQ/JPype1/\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jpype1\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/62/0f312d578e0165e9b5e8fcae0291f7ee83783b3805f59071006b21229d55/JPype1-0.7.1.tar.gz\n",
      "Building wheels for collected packages: jpype1\n",
      "  Running setup.py bdist_wheel for jpype1 ... \u001b[?25lerror\n",
      "  Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-_EZaDp/jpype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-wheel-NJjQ9o --python-tag cp27:\n",
      "  /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'use_scm_version'\n",
      "    warnings.warn(msg)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.6-intel-2.7\n",
      "  creating build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcollection.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcomparable.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_classpath.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jtypes.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_pykeywords.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jproxy.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_gui.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_darwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/nio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jstring.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_cygwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/__init__.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jboxed.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/types.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/beans.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jvmfinder.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/imports.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcustomizer.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_core.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jinit.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_linux.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jarray.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jobject.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/pickle.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jclass.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_windows.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jexception.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/reflect.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jpackage.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  running build_ext\n",
      "  running build_java\n",
      "  Using Jar cache\n",
      "  creating build/lib\n",
      "  creating build/lib/org\n",
      "  creating build/lib/org/jpype\n",
      "  creating build/lib/org/jpype/classloader\n",
      "  copying native/jars/org/jpype/classloader/JPypeClassLoader.class -> build/lib/org/jpype/classloader\n",
      "  copying native/jars/org.jpype.jar -> build/lib\n",
      "  running build_thunk\n",
      "  Building thunks\n",
      "    including thunk build/lib/org/jpype/classloader/JPypeClassLoader.class\n",
      "    including thunk build/lib/org.jpype.jar\n",
      "  setupext/build_ext.py:87: FeatureNotice: Turned ON Numpy support for fast Java array access\n",
      "    FeatureNotice)\n",
      "  building '_jpype' extension\n",
      "  creating build/temp.macosx-10.6-intel-2.7\n",
      "  creating build/temp.macosx-10.6-intel-2.7/build\n",
      "  creating build/temp.macosx-10.6-intel-2.7/build/src\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native/python\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native/common\n",
      "  /usr/bin/clang -DNDEBUG -g -fwrapv -O3 -Wall -stdlib=libc++ -DMACOSX=1 -DHAVE_NUMPY=1 -Inative/common/include -Inative/python/include -Ibuild/src -Inative/jni_include -I/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/include -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c build/src/jp_thunk.cpp -o build/temp.macosx-10.6-intel-2.7/build/src/jp_thunk.o -ggdb\n",
      "  clang: error: invalid deployment target for -stdlib=libc++ (requires OS X 10.7 or later)\n",
      "  error: command '/usr/bin/clang' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for jpype1\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for jpype1\n",
      "Failed to build jpype1\n",
      "\u001b[31mmarkdown 3.1.1 has requirement setuptools>=36, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorboard 2.1.0 has requirement setuptools>=41.0.0, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-auth 1.10.0 has requirement setuptools>=40.3.0, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jpype1\n",
      "  Running setup.py install for jpype1 ... \u001b[?25lerror\n",
      "    Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-_EZaDp/jpype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-record-I7O3fc/install-record.txt --single-version-externally-managed --compile:\n",
      "    /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'use_scm_version'\n",
      "      warnings.warn(msg)\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build/lib.macosx-10.6-intel-2.7\n",
      "    creating build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcollection.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcomparable.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_classpath.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jtypes.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_pykeywords.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jproxy.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_gui.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_darwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/nio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jstring.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_cygwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/__init__.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jboxed.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/types.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/beans.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jvmfinder.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/imports.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcustomizer.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_core.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jinit.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_linux.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jarray.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jobject.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/pickle.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jclass.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_windows.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jexception.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/reflect.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jpackage.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    running build_ext\n",
      "    running build_java\n",
      "    Using Jar cache\n",
      "    copying native/jars/org/jpype/classloader/JPypeClassLoader.class -> build/lib/org/jpype/classloader\n",
      "    copying native/jars/org.jpype.jar -> build/lib\n",
      "    running build_thunk\n",
      "    Building thunks\n",
      "      including thunk build/lib/org/jpype/classloader/JPypeClassLoader.class\n",
      "      including thunk build/lib/org.jpype.jar\n",
      "    setupext/build_ext.py:87: FeatureNotice: Turned ON Numpy support for fast Java array access\n",
      "      FeatureNotice)\n",
      "    building '_jpype' extension\n",
      "    creating build/temp.macosx-10.6-intel-2.7\n",
      "    creating build/temp.macosx-10.6-intel-2.7/build\n",
      "    creating build/temp.macosx-10.6-intel-2.7/build/src\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native/python\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native/common\n",
      "    /usr/bin/clang -DNDEBUG -g -fwrapv -O3 -Wall -stdlib=libc++ -DMACOSX=1 -DHAVE_NUMPY=1 -Inative/common/include -Inative/python/include -Ibuild/src -Inative/jni_include -I/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/include -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c build/src/jp_thunk.cpp -o build/temp.macosx-10.6-intel-2.7/build/src/jp_thunk.o -ggdb\n",
      "    clang: error: invalid deployment target for -stdlib=libc++ (requires OS X 10.7 or later)\n",
      "    error: command '/usr/bin/clang' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mCommand \"/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-_EZaDp/jpype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-record-I7O3fc/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-_EZaDp/jpype1/\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25hCollecting konlpy\n",
      "  Using cached https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.6 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from konlpy) (1.16.6)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from konlpy) (3.8.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from konlpy) (4.6.0)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/62/0f312d578e0165e9b5e8fcae0291f7ee83783b3805f59071006b21229d55/JPype1-0.7.1.tar.gz\n",
      "Collecting lxml>=4.1.0 (from konlpy)\n",
      "  Using cached https://files.pythonhosted.org/packages/d0/70/a067810a5b6ddfea32600bfbbd9916dae4d4b5b0754d49c50208c7d00663/lxml-4.4.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting colorama (from konlpy)\n",
      "  Using cached https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.11.1 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tweepy>=3.7.0->konlpy) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tweepy>=3.7.0->konlpy) (1.13.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2017.7.27.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Building wheels for collected packages: JPype1\n",
      "  Running setup.py bdist_wheel for JPype1 ... \u001b[?25lerror\n",
      "  Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-HIIcd4/JPype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-wheel-Lvd3Pg --python-tag cp27:\n",
      "  /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'use_scm_version'\n",
      "    warnings.warn(msg)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.6-intel-2.7\n",
      "  creating build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcollection.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcomparable.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_classpath.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jtypes.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_pykeywords.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jproxy.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_gui.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_darwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/nio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jstring.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_cygwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/__init__.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jboxed.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/types.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/beans.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jvmfinder.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/imports.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jcustomizer.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_core.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jinit.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_linux.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jarray.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jobject.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/pickle.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jclass.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_windows.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jexception.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/reflect.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  copying jpype/_jpackage.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "  running build_ext\n",
      "  running build_java\n",
      "  Using Jar cache\n",
      "  creating build/lib\n",
      "  creating build/lib/org\n",
      "  creating build/lib/org/jpype\n",
      "  creating build/lib/org/jpype/classloader\n",
      "  copying native/jars/org/jpype/classloader/JPypeClassLoader.class -> build/lib/org/jpype/classloader\n",
      "  copying native/jars/org.jpype.jar -> build/lib\n",
      "  running build_thunk\n",
      "  Building thunks\n",
      "    including thunk build/lib/org/jpype/classloader/JPypeClassLoader.class\n",
      "    including thunk build/lib/org.jpype.jar\n",
      "  setupext/build_ext.py:87: FeatureNotice: Turned ON Numpy support for fast Java array access\n",
      "    FeatureNotice)\n",
      "  building '_jpype' extension\n",
      "  creating build/temp.macosx-10.6-intel-2.7\n",
      "  creating build/temp.macosx-10.6-intel-2.7/build\n",
      "  creating build/temp.macosx-10.6-intel-2.7/build/src\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native/python\n",
      "  creating build/temp.macosx-10.6-intel-2.7/native/common\n",
      "  /usr/bin/clang -DNDEBUG -g -fwrapv -O3 -Wall -stdlib=libc++ -DMACOSX=1 -DHAVE_NUMPY=1 -Inative/common/include -Inative/python/include -Ibuild/src -Inative/jni_include -I/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/include -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c build/src/jp_thunk.cpp -o build/temp.macosx-10.6-intel-2.7/build/src/jp_thunk.o -ggdb\n",
      "  clang: error: invalid deployment target for -stdlib=libc++ (requires OS X 10.7 or later)\n",
      "  error: command '/usr/bin/clang' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for JPype1\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for JPype1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build JPype1\n",
      "\u001b[31mmarkdown 3.1.1 has requirement setuptools>=36, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorboard 2.1.0 has requirement setuptools>=41.0.0, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mgoogle-auth 1.10.0 has requirement setuptools>=40.3.0, but you'll have setuptools 28.8.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: JPype1, lxml, colorama, konlpy\n",
      "  Running setup.py install for JPype1 ... \u001b[?25lerror\n",
      "    Complete output from command /Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-HIIcd4/JPype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-record-Gw0dke/install-record.txt --single-version-externally-managed --compile:\n",
      "    /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'use_scm_version'\n",
      "      warnings.warn(msg)\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build/lib.macosx-10.6-intel-2.7\n",
      "    creating build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcollection.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcomparable.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_classpath.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jtypes.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_pykeywords.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jproxy.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_gui.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_darwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/nio.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jstring.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_cygwin.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/__init__.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jboxed.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/types.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/beans.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jvmfinder.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/imports.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jcustomizer.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_core.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jinit.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_linux.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jarray.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jobject.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/pickle.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jclass.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_windows.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jexception.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/reflect.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    copying jpype/_jpackage.py -> build/lib.macosx-10.6-intel-2.7/jpype\n",
      "    running build_ext\n",
      "    running build_java\n",
      "    Using Jar cache\n",
      "    copying native/jars/org/jpype/classloader/JPypeClassLoader.class -> build/lib/org/jpype/classloader\n",
      "    copying native/jars/org.jpype.jar -> build/lib\n",
      "    running build_thunk\n",
      "    Building thunks\n",
      "      including thunk build/lib/org/jpype/classloader/JPypeClassLoader.class\n",
      "      including thunk build/lib/org.jpype.jar\n",
      "    setupext/build_ext.py:87: FeatureNotice: Turned ON Numpy support for fast Java array access\n",
      "      FeatureNotice)\n",
      "    building '_jpype' extension\n",
      "    creating build/temp.macosx-10.6-intel-2.7\n",
      "    creating build/temp.macosx-10.6-intel-2.7/build\n",
      "    creating build/temp.macosx-10.6-intel-2.7/build/src\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native/python\n",
      "    creating build/temp.macosx-10.6-intel-2.7/native/common\n",
      "    /usr/bin/clang -DNDEBUG -g -fwrapv -O3 -Wall -stdlib=libc++ -DMACOSX=1 -DHAVE_NUMPY=1 -Inative/common/include -Inative/python/include -Ibuild/src -Inative/jni_include -I/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy/core/include -I/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -c build/src/jp_thunk.cpp -o build/temp.macosx-10.6-intel-2.7/build/src/jp_thunk.o -ggdb\n",
      "    clang: error: invalid deployment target for -stdlib=libc++ (requires OS X 10.7 or later)\n",
      "    error: command '/usr/bin/clang' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-HIIcd4/JPype1/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-record-Gw0dke/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /private/var/folders/sv/p6bxgfmn2kxg05bt8k_5thqw0000gn/T/pip-install-HIIcd4/JPype1/\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# 맥인 경우만 실행\n",
    "!CFLAGS=\"-stdlib=libc++\" pip install jpype1\n",
    "!export MACOSX_DEPLOYMENT_TARGET=10.10\n",
    "!CFLAGS='-stdlib=libc++' pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'konlpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6926d46fbe20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtwitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmalist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'나는 누구이고 여기는 어디인가.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmalist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "malist = twitter.pos('나는 누구이고 여기는 어디인가.', norm=True, stem=True)\n",
    "print(malist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마르코프 체인과 문장생성\n",
    "* 마르코프 체인 : 과거의 상태와 무관하게 현재의 상태만을 기반으로 다음 상태를 선택\n",
    "* 마르코프 체인 문장 생성\n",
    "    1. 문장을 형태소(또는 단어)로 분할\n",
    "    2. 단어의 전후 단어를 n개씩 모아 딕셔너리 생성\n",
    "        * 예:n=3) 나는 누구이고 여기는 어디인가\n",
    "        * [나,는,누구], [는, 누구, 이고], [누구, 이고, 여기], [이고, 여기, 는], [여기, 는, 어디], [는, 어디, 인가]ㅓ\n",
    "        * 어떤 형태소 다음에 나타날 요소를 선택할 수 있다.\n",
    "    3. 딕셔너리로 임의의 문장 생성\n",
    "        * 예) 등록된 예문으로 새 문장 만들기\n",
    "            * 등록된 문장\n",
    "                * 개,도,닷새,가,되면,주인,을,안다.\n",
    "                * 기르던,개,에게,다리,가,물렸다\n",
    "                * 닭,쫒던,개,지붕,쳐다,보듯,한다\n",
    "                * 똥,묻은,개,가,겨,묻은,개,나무란다.\n",
    "            * 개로 시작하는 새 문장\n",
    "                * 개 : 도/에게/지붕/가, \n",
    "                * 개가 :  되면/물렸다/겨\n",
    "                * 개가 되면 :  주인\n",
    "                * 개가 되면 주인 : 을\n",
    "                * 개가 되면 주인을 :  안다\n",
    "                * 개가 되면 주인을 안다\n",
    "* LSTM으로 전후 단어의 연관성을 학습\n",
    "    * 확률이 높은 단어 선택\n",
    "    * 자연스런 문장 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마르코프 체인을 이용한 챗봇 만들기\n",
    "* Eliza online demo : http://www.masswerk.at/elizabot/\n",
    "    * 환자 중심 상담 이론 기반\n",
    "    * 상대의 말을 반복하는 단순한 기능\n",
    "    * 영어만 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from konlpy.tag import Twitter\n",
    "import os, re, json, random\n",
    "\n",
    "script_file = './assets/script.txt'\n",
    "dict_file = \"./chatbot-data.json\"\n",
    "dic = {}\n",
    "twitter = Twitter()\n",
    "# 딕셔너리에 단어 등록하기 --- (※1)\n",
    "def register_dic(words, save=True):\n",
    "    global dic\n",
    "    if len(words) == 0: return\n",
    "    tmp = [\"@\"]\n",
    "    for i in words:\n",
    "        word = i[0]\n",
    "        if word == \"\" or word == \"\\r\\n\" or word == \"\\n\": continue\n",
    "        tmp.append(word)\n",
    "        if len(tmp) < 3: continue\n",
    "        if len(tmp) > 3: tmp = tmp[1:]\n",
    "        set_word3(dic, tmp)\n",
    "        if word == \".\" or word == \"?\":\n",
    "            tmp = [\"@\"]\n",
    "            continue\n",
    "    # 딕셔너리가 변경될 때마다 저장하기\n",
    "    if save:\n",
    "        json.dump(dic, open(dict_file,\"w\", encoding=\"utf-8\"))\n",
    "# 딕셔너리에 글 등록하기\n",
    "def set_word3(dic, s3):\n",
    "    w1, w2, w3 = s3\n",
    "    if not w1 in dic: dic[w1] = {}\n",
    "    if not w2 in dic[w1]: dic[w1][w2] = {}\n",
    "    if not w3 in dic[w1][w2]: dic[w1][w2][w3] = 0\n",
    "    dic[w1][w2][w3] += 1\n",
    "# 문장 만들기 --- (※2)\n",
    "def make_sentence(head):\n",
    "    if not head in dic: return \"\"\n",
    "    ret = []\n",
    "    if head != \"@\": ret.append(head)        \n",
    "    top = dic[head]\n",
    "    w1 = word_choice(top)\n",
    "    w2 = word_choice(top[w1])\n",
    "    ret.append(w1)\n",
    "    ret.append(w2)\n",
    "    while True:\n",
    "        if w1 in dic and w2 in dic[w1]:\n",
    "            w3 = word_choice(dic[w1][w2])\n",
    "        else:\n",
    "            w3 = \"\"\n",
    "        ret.append(w3)\n",
    "        if w3 == \".\" or w3 == \"？ \" or w3 == \"\": break\n",
    "        w1, w2 = w2, w3\n",
    "    ret = \"\".join(ret)\n",
    "    # 띄어쓰기\n",
    "    params = urllib.parse.urlencode({\n",
    "        \"q\": ret\n",
    "    })\n",
    "    # 네이버 맞춤법 검사기를 사용합니다.\n",
    "    try:\n",
    "        url = \"https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy?where=nexearch&color_blindness=0&\" + params\n",
    "        data = urllib.request.urlopen(url)\n",
    "        data = data.read().decode(\"utf-8\")\n",
    "        data = json.loads(data)\n",
    "        data = data[\"message\"][\"result\"][\"html\"]\n",
    "        data = soup = BeautifulSoup(data, \"html.parser\").getText()\n",
    "        # 리턴\n",
    "    except :\n",
    "        data = ret\n",
    "    return data\n",
    "def word_choice(sel):\n",
    "    keys = sel.keys()\n",
    "    return random.choice(list(keys))\n",
    "# 챗봇 응답 만들기 --- (※3)\n",
    "def make_reply(text):\n",
    "    # 단어 학습시키기\n",
    "    if not text[-1] in [\".\", \"?\"]: text += \".\"\n",
    "    words = twitter.pos(text)\n",
    "    register_dic(words)\n",
    "    # 사전에 단어가 있다면 그것을 기반으로 문장 만들기\n",
    "    for word in words:\n",
    "        face = word[0]\n",
    "        if face in dic: return make_sentence(face)\n",
    "    return make_sentence(\"@\")\n",
    "# 딕셔너리가 있다면 읽어 들이기\n",
    "if os.path.exists(dict_file):\n",
    "    dic = json.load(open(dict_file,\"r\"))\n",
    "    print(\"dictionary loaded.\")\n",
    "else:\n",
    "    print(\"no dictionary. trainning chatbot is needed.\")\n",
    "    \n",
    "if os.path.exists(script_file):\n",
    "    f = open(script_file, 'rt', encoding='UTF8')\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line : \n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line == \"\"  :\n",
    "            continue\n",
    "        if not line[-1] in [\".\", \"?\"]: line += \".\"\n",
    "        words = twitter.pos(line)\n",
    "        #print(line)\n",
    "        register_dic(words, save=False)\n",
    "    json.dump(dic, open(dict_file,\"w\", encoding=\"utf-8\"))\n",
    "    print(\"trained using script .\")\n",
    "else:\n",
    "    print(\"no script file. \")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"대화를 종료하시려면 'exit'를 입력하세요.\")\n",
    "while True:\n",
    "    txt = input(\"You :\")\n",
    "    if txt == \"exit\":\n",
    "        print(\"Bye~\")\n",
    "        break\n",
    "    reply = make_reply(txt)\n",
    "    print(\"Bot :%s\"%reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마르코프 체인과 LSTM을 이용한 문장 자동 생성기 예제\n",
    "* 박경리 토지 다운로드\n",
    "    * 국립국어원 : https://ithub.korean.go.kr/user/total/database/corpusView.do?boardSeq=2&articleSeq=2081&boardGb=T&isInsUpd=&boardType=CORPUS\n",
    "    * ./data/BEXX004.txt\n",
    "* 필요 라이브러리\n",
    "    * `!pip install beautifulsoup4`\n",
    "    * `!pip install konlpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "#from tensorflow.keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random, sys\n",
    "\n",
    "fp = codecs.open(\"./data/BEXX0004.txt\", \"r\", encoding=\"utf-16\")\n",
    "soup = BeautifulSoup(fp, \"html.parser\")\n",
    "body = soup.select_one(\"body\")\n",
    "text = body.getText() + \" \"\n",
    "print(text)\n",
    "print('코퍼스의 길이: ', len(text))\n",
    "# 문자를 하나하나 읽어 들이고 ID 붙이기\n",
    "chars = sorted(list(set(text)))\n",
    "print(chars)\n",
    "print('사용되고 있는 문자의 수:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars)) # 문자 → ID\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars)) # ID → 문자\n",
    "\n",
    "# 텍스트를 maxlen개의 문자로 자르고 다음에 오는 문자 등록하기\n",
    "maxlen = 20\n",
    "step = 3   # 문장 마다 3글자씩 건너서 생성\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('학습할 구문의 수:', len(sentences))\n",
    "    \n",
    "print('텍스트를 ID 벡터로 변환합니다...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "# 모델 구축하기(LSTM)\n",
    "print('모델을 구축합니다...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "model.fit(X, y, batch_size=128, nb_epoch=30, verbose=0) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 후보를 배열에서 꺼내기\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    ret = np.argmax(probas)\n",
    "    #print(f\"sample {temperature}, {np.argmax(preds)}, {ret}\")\n",
    "    return ret\n",
    "\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "generated = ''\n",
    "sentence = text[start_index: start_index + maxlen]\n",
    "generated += sentence\n",
    "print('--- 시드 = \"' + sentence + '\"')\n",
    "sys.stdout.write(generated)\n",
    "# 시드를 기반으로 텍스트 자동 생성\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "    # 다음에 올 문자를 예측하기\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds)\n",
    "    #next_index = np.argmax(preds)#sample(preds, diversity)\n",
    "    next_char = indices_char[next_index]\n",
    "    # 출력하기\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 텍스트 데이터 다루기\n",
    "* 텍스트가 가장 흔한 시퀀스 데이타\n",
    "* 비전이 픽셀에 대한 패턴인식\n",
    "* 자연어처리는 단어, 문장, 문단에 대한 패턴인식\n",
    "* 입력데이타는 텍스트 원본일 수 없어서 텍스트 벡터화 필요\n",
    "    * 텍스트를 단어로 나누고 각 단어를 하나의 벡터로 변환\n",
    "    * 텍스트를 문자로 나누고 각 문자를 하나의 벡터로 변환\n",
    "\n",
    "* 어떻게 변환하든 이것을 토큰이라한다.\n",
    "* 토큰에 수치형 벡터 연결\n",
    "    * 원핫 인코딩(One-hot encoding)\n",
    "    * 토큰 임베딩(Token Embbeding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "* 토큰을 벡터로 변환하는 가장 일반적인 방법\n",
    "* 모든 단어(문자)에 고유한 인텍스 부여, 인텍스를 원핫 인코딩\n",
    "    * 예) I love you\n",
    "        * I : 0, [1,0,0]\n",
    "        * love : 1, [0,1,0\n",
    "        * you : 2, [0,0,1]\n",
    "* 단점\n",
    "    * 희소 배열 생성(대부분이 0)        \n",
    "    * 단어(문자) 수가 많아 지면 차원이 너무 비대해진다.\n",
    "    * 단어(문자)에 유사도 없음\n",
    "    * 단어(문자)의 순서에 대한 정보 없음\n",
    "* keras 원핫인코딩 유틸\n",
    "    * keras.preprocessing.text.Tokenizer\n",
    "    \n",
    "\n",
    "### Token Embbeding - Word2Vec\n",
    "* 원핫 인코딩 단점 보완\n",
    "* 밀집, 저차원\n",
    "* Word2Vec(Skip gram)\n",
    "* window size에 맞게 이웃하는 단어 선택\n",
    "* 각 단어를 one-hot encoding으로 변환\n",
    "* 예) king brave man/ queen beautiful women(window_size=1)\n",
    "    * king[1,0,0,0,0,0] - brave[0,1,0,0,0,0]\n",
    "    * brave[0,1,0,0,0,0] - man[0,0,1,0,0,0]\n",
    "    * brave[0,1,0,0,0,0] - king[1,0,0,0,0,0]\n",
    "    * queen[0,0,1,0,0,0] - beautiful[0,0,0,0,1,0]\n",
    "    * beautiful[0,0,0,0,1,0] - women[0,0,0,0,0,1]\n",
    "    * women[0,0,0,0,0,1] - beautiful[0,0,0,0,1,0]\n",
    "*  hidden layer가 2인 네트워크에 input과 output으로 전달해서 학습\n",
    "    * ![](https://i.imgur.com/vjVYupm.png)\n",
    "* 학습한 W1, W2가 입력 단어에 대한 벡터\n",
    "   * king[1,1]\n",
    "   * brave[1,2]\n",
    "   * man[1,3]\n",
    "   * queen[5,5]\n",
    "   * beautiful[5,6]\n",
    "   * women[5,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "word2vec = {\"king\":np.array([1,1]), \"brave\":np.array([1,2]),\"man\": np.array([1,3]), \"queen\":np.array([5,5]), \"beautiful\":np.array([5,6]),\"women\": [5,7]}\n",
    "for k, v in word2vec.items():\n",
    "    plt.annotate(k, v)\n",
    "    plt.scatter(v[0], v[1])\n",
    "\n",
    "king_man_women = word2vec['king'] - word2vec['man'] + word2vec['women']    \n",
    "print(\"king-man+women = \" , king_man_women)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \n",
    "\n",
    "###  텍스트 유사도 표현\n",
    "* Bag of Words\n",
    "    * 각 단어의 출연 빈도를 표시\n",
    "* N-gram\n",
    "    * 텍스트에서 단어나 문자의 n-그램을 추출하여 그것을 하나의 벡터로 변환\n",
    "        * n-gram: 문장에서 이웃한 N개의 문자\n",
    "            * 예)\"The cat sat on the mat\"\n",
    "            * 2-gram : \"The cat\", \"cat on\", \"on the\", \"the mat\"\n",
    "            * 3-gram : \"The cat sat\", \"cat sat on\", \"sat on the\", \"on the mat\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 구현 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    stop_words = ['is', 'a', 'will', 'be']\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "corpus = remove_stop_words(corpus) # stop word 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "\n",
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "    \n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for text in corpus:\n",
    "    print(text)\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X).astype(np.float32)\n",
    "Y_train = np.asarray(Y).astype(np.float32)\n",
    "\n",
    "\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 \n",
    "init = tf.initializers.GlorotUniform()\n",
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(init([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random.normal([1])) #bias\n",
    "\n",
    "\n",
    "# output layer\n",
    "W2 = tf.Variable(init([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "for i in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hidden_layer = tf.add(tf.matmul(X_train,W1), b1)\n",
    "        prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "        cost = tf.reduce_mean(-tf.reduce_sum(Y_train * tf.math.log(prediction), axis=[1]))\n",
    "        #cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y_train, logits=prediction))\n",
    "    grads = tape.gradient(cost, [W1, b1, W2, b2])\n",
    "    optimizer.apply_gradients(zip(grads, [W1, b1, W2, b2]))    \n",
    "    if i % 3000 == 0:\n",
    "        print('epochs '+str(i)+' cost is : ',cost.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = (W1 + b1).numpy()\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "plt.figure(figsize=(10,10))  \n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    plt.plot(x1, x2, 'b.')\n",
    "    plt.annotate(word, (x1,x2 ))\n",
    "    \n",
    "      \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
