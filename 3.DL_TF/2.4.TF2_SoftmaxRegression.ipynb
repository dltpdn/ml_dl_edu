{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2 Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Classification\n",
    "* 여러 클래스를 분류하는 방법\n",
    "    * 이진 분류기를 여러번 쓰는 방법에 비해 행렬 연산을 하는 것이 효과적\n",
    "* 이진 분류기를 여러번 쓰는 것\n",
    "    * 클래스 A 모델:\n",
    "    $\\begin{bmatrix}x_1 & x_2 \\end{bmatrix}\n",
    "    \\begin{bmatrix}w_{a1} \\\\ w_{a2}\\end{bmatrix}\n",
    "    = \\begin{bmatrix}w_{a1}x_1 +w_{a2}x_2\\end{bmatrix}$\n",
    "    * 클래스 B 모델:\n",
    "    $\\begin{bmatrix}x_1 & x_2 \\end{bmatrix}\n",
    "    \\begin{bmatrix}w_{b1} \\\\ w_{b2}\\end{bmatrix}\n",
    "    =\\begin{bmatrix}w_{b1}x_1 +w_{b2}x_2\\end{bmatrix}$\n",
    "    * 클래스 C 모델:$\\begin{bmatrix}x_1 & x_2 \\end{bmatrix}\n",
    "    \\begin{bmatrix}w_{c1} \\\\ w_{c2}\\end{bmatrix}\n",
    "    =\\begin{bmatrix}w_{c1}x_1 +w_{c2}x_2\\end{bmatrix}$\n",
    "* 하나의 행렬로 계산\n",
    "    * $\\begin{bmatrix}x_1 & x_2 \\end{bmatrix}\n",
    "    \\begin{bmatrix}w_{a1}  & w_{b1} & w_{c1} \\\\ w_{a2} & w_{b2} &w_{c2}  \\end{bmatrix}\n",
    "    = \\begin{bmatrix}w_{a1}x_1 +w_{a2}x_2 & w_{b1}x_1 +w_{b2}x_2 & w_{c1}x_1 +w_{c2}x_2 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoing\n",
    "* 범주형 데이타를 숫자로 표현할 방법 필요\n",
    "    * 예) {개:0, 고양이:1, 닭:2}\n",
    "* 범주형 숫자 데이타를 열거형으로 표현\n",
    "   * 숫자가 크기의 의미를 갖는 문제 해결\n",
    "   * 문제 사례)\n",
    "       * 고양이 > 개 : True\n",
    "       * $닭 - 개 = 2$\n",
    "* One-Hot Encoding\n",
    "    * 한 요소만 1이고 나머지는 0으로 구성된 배열\n",
    "    * 표현할 값에 해당하는 인덱스 요소만 1로 설정\n",
    "    * `np.eye()` 함수와 Fancy Indexing으로 손쉽게 생성\n",
    "        * `np.eye()`: 대각 행렬 생성\n",
    "        * 예) `np.eye(3)[[0, 1, 1, 0, 2]]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)[[0, 1, 1, 0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax 함수\n",
    "* 다항 로지스틱 회귀\n",
    "* Sigmoid 대신 Softmax 함수 사용\n",
    "    * Softmax : 각 출력 값은 0~1 사이, 모든 클래스의 값의 합은 1, 확율로 사용 가능\n",
    "    * sigmoid 보다 좋은 이유 : 하나의 클래스가 높은 값을 갖으면 나머지 클래스는 아주 작은 값, 배타적\n",
    "* $\\displaystyle \\hat{P_k} = \\frac{e^{z_i}}{e^{z_0} + e^{z_1} + e^{z_2}... + e^{z_k}}= \\frac{e^{z_i}}{\\sum_{j=0}^ke^{z_k}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Prediction\n",
    "* Softmax 결과에서 확률이 가장 높은 클래스 반환\n",
    "* $\\hat{y} = argmax(\\hat{p})$\n",
    "* `np.argmax(p)`\n",
    "* `tf.argmax(p)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [0.5 0.3 0.9]\n",
      "probability: [0.30206411 0.24730918 0.45062671] sum: 1.0\n",
      "argmax: 2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logits = np.array([0.5, 0.3, 0.9])\n",
    "print(\"logits\", logits)\n",
    "p = np.exp(logits) / np.sum(np.exp(logits))\n",
    "print(\"probability:\", p, \"sum:\", np.sum(p))\n",
    "print(\"argmax:\", np.argmax(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy\n",
    "* 소프트 맥스의 비용함수 :\n",
    "$\\displaystyle J(\\theta) =  -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^ky_k^{(i)}log(\\hat{p_k})$\n",
    "* 소프트맥스를 통과한 결과값은 어떤 특정한 클래스만 높은 값을 갖고 나머지 클래스는 아주 작은 값을 갖는다.\n",
    "여기에 y는 정답 클래스인 경우만 1을 나머지는 0을 가지고 있으므로 소프트맥스를 통과한 결과와 y를 곱하는 것만으로도 정답만 값이 있고 틀린 결과는 0이다. 이 때 소프트맥스를 통과한 값을 $-log(p)$함수를 적용하면 0에 가까운 값은 매우 커지고 1에 가까운 값은 0에 가까워 진다.\n",
    "따라서 $y\\cdot -log(p)$는 정답과 틀리면 매우 큰 값 맞으면 0에 가까운 값이 나오므로 비용함수로 적합하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no+IWEXEZFbeIiMuouEVEXOY/AYHMFwXjkfdBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def drawLogNegative():\n",
    "    p = np.linspace(0, 1, 100)\n",
    "    y = -tf.math.log(p)\n",
    "    plt.plot(p, y)\n",
    "drawLogNegative()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient of Cross Entropy\n",
    "* $\\displaystyle \\nabla J(\\theta) = \\frac{1}{m}\\sum_{i=1}^m(\\hat{p}_k^{(i)} - y_k^{(i)})x^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_data = np.array([[-0.1, 1.4],\n",
    "              [-0.5, 0.2],\n",
    "              [ 1.3, 0.9],\n",
    "              [-0.6, 0.4],\n",
    "              [-1.6, 0.2],\n",
    "              [ 0.2, 0.2],\n",
    "              [-0.3,-0.4],\n",
    "              [ 0.7,-0.8],\n",
    "              [ 1.1,-1.5],\n",
    "              [-1.0, 0.9],\n",
    "              [-0.5, 1.5],\n",
    "              [-1.3,-0.4],\n",
    "              [-1.4,-1.2],\n",
    "              [-0.9,-0.7],\n",
    "              [ 0.4,-1.3],\n",
    "              [-0.4, 0.6],\n",
    "              [ 0.3,-0.5],\n",
    "              [-1.6,-0.7],\n",
    "              [-0.5,-1.4],\n",
    "              [-1.0,-1.4]], dtype=np.float32)\n",
    "y_label = np.array([0, 0, 1, 0, 2, 1, 1, 1, 1, 0, 0, 2, 2, 2, 1, 0, 1, 2, 2, 2])\n",
    "y_data =  np.eye(3)[y_label]\n",
    "\n",
    "colormap = np.array(['r', 'g', 'b'])\n",
    "plt.scatter(x_data[:,0], x_data[:,1], s=50, c=colormap[y_label])\n",
    "plt.title('Input', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random.normal([2, 3]))\n",
    "b = tf.Variable(tf.random.normal([3]))\n",
    "learing_rate = 0.05\n",
    "\n",
    "for step in range(5001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.nn.softmax(tf.matmul(x_data, W) + b)\n",
    "        #cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_data, logits=hypothesis))\n",
    "    d_W, d_b = tape.gradient(cost, [W, b])\n",
    "    W.assign_sub(learing_rate * d_W)\n",
    "    b.assign_sub(learing_rate * d_b)\n",
    "    if step % 200 == 0:\n",
    "            print(\"step:{}, cost:{}\".format(step, cost))\n",
    "\n",
    "predict = tf.argmax(hypothesis, axis=1, name='predict')\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, y_label),tf.float32))\n",
    "print(\"Accuracy:{}\".format(accuracy))\n",
    "print(predict)\n",
    "\n",
    "plt.title('Predict', size=20)\n",
    "colormap = np.array(['r', 'g', 'b'])\n",
    "plt.scatter(x_data[:,0], x_data[:,1], s=50, c=colormap[predict.numpy()])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
