{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2 Keras API\n",
    "* keras == tf.keras\n",
    "    * Graph와 Layer 구조와 생성을 추상화\n",
    "* keras.Sequencial\n",
    "    * Model 생성\n",
    "    * Layer stack\n",
    "    * `add(Layer)` : 계층 추가\n",
    "    * `model.trainable_variables` : 훈련에 사용할 모든 변수\n",
    "    * `call(x)` : prediction\n",
    "* keras.layers\n",
    "    * Layer를 추상화\n",
    "    * keras.layers.Dense\n",
    "        * 가장 일반적인 완전연결층(밀집층)\n",
    "    * keras.layers.RNN, LSTM\n",
    "        * 시계열이나 시퀀스는 3D로 텐서로 표현\n",
    "    * keras.layers.Conv2D\n",
    "        * 이미지는 4D로 저장되고 CNN\n",
    "    * 생성할때 출력층은 필수고 입력 층은 input_shape 인자로 넘기는데, 샘플 축은 생략\n",
    "        * 예를 들어 `Dense(32, input_shape=(784,))` 이면 입력이 n x 784, 이때 n은 몇개든 상관없슴\n",
    "        * 만약 `Dense(10)` 이렇게 입력층 생략하면 앞 층의 출력의 갯수로 자동 지정\n",
    "* 손실함수\n",
    "    * `tf.keras.losses`\n",
    "    * 2개 클래스 : \n",
    "        `BinaryCrossentropy`\n",
    "    * 여러 클래스 분류 : \n",
    "        * `tf.kearas.losses.CategoricalCrossentropy()`  : One-Hot encoding Label에 대한 crossEntropy 손실함수\n",
    "        * `tf.keras.losses.SparseCategoricalCrossentropy()` : Label에 대한(one-hot 안한) crossEntropy 손실함수\n",
    "    * 회귀 : \n",
    "        * `MSE` : 평균제곱오차\n",
    "* 성능 지표 측정\n",
    "    * `tf.keras.metrics`\n",
    "        * `Mean`\n",
    "        * `SparseCategoricalAccuracy`\n",
    "* Neural Nework 생성 절차\n",
    "    * 층(Layer) 갯수\n",
    "    * 입력 / 출력 갯수\n",
    "    * 손실함수 선택\n",
    "    * 옵티마이저 선택\n",
    "    * 성능 추적 지표 선택\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_input = 28*28\n",
    "n_L1 = 300\n",
    "n_L2 = 100\n",
    "n_output = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, n_input)/255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, n_input)/255.0\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "batch_size = 100\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(n_L1, activation=tf.nn.relu, input_shape=(n_input,)),  # 입력의 형태가 필요합니다.\n",
    "    tf.keras.layers.Dense(n_L2, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(n_output, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "step = 0\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "validate_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='validation_accuracy')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in train_ds:\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = model(x, training=True)\n",
    "            #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=predictions))\n",
    "            cost = loss_object(y, predictions)\n",
    "        grads = tape.gradient(cost, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        train_loss(cost)\n",
    "        train_accuracy(y, predictions)\n",
    "        validate_accuracy(y_valid, model(X_valid, training=False))\n",
    "    print(f\"epoch:{epoch}, cost:{train_loss.result()}, \\\n",
    "              test_accuracy:{train_accuracy.result()}, validate_accuracy:{validate_accuracy.result()}\")\n",
    "\n",
    "'''\n",
    "for x, y in test_ds:\n",
    "    predictions = model(x, training=False)\n",
    "    test_accuracy(y, predictions)\n",
    "'''\n",
    "test_accuracy(y_test,  model(X_test, training=False))\n",
    "print(f\"test acc:{test_accuracy.result()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras High-Level API\n",
    "* High-Level Neural Networks API\n",
    "* 간결한 문법\n",
    "* 지원하는 백엔드(Back-end) 엔진\n",
    "    * Tensorflow\n",
    "    * CNTK\n",
    "    * Theano (최초 Theano 겨냥해서 시작)\n",
    "* 백엔드 종속성 제거\n",
    "* Tensorflow의 공식 High-level API로 선정\n",
    "* 가장 인기 있는 인공지능 라이브러리\n",
    "\n",
    "![image.png](https://i.imgur.com/APiGGgd.png)\n",
    "![image.png](https://i.imgur.com/rlDMvPH.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.compile()\n",
    "* model.fit()\n",
    "* model.evaluate()\n",
    "* model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_input = 28*28\n",
    "n_L1 = 300\n",
    "n_L2 = 100\n",
    "n_output = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "#X_train = X_train.astype(np.float32).reshape(-1, n_input)/255.0\n",
    "#X_test = X_test.astype(np.float32).reshape(-1, n_input)/255.0\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(n_L1, activation=tf.nn.relu ), #, input_shape=(n_input,)),  # 입력의 형태가 필요합니다.\n",
    "    tf.keras.layers.Dense(n_L2, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(n_output, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_valid, y_valid))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Test Accuracy:{}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import img2data\n",
    "img_path = './img/0458.png'\n",
    "#img_path = './img/1369.png'\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "numbers = img2data.img2digits(image, (28,28), border=4, reshape=False)\n",
    "Z = model.predict(np.float32(numbers)/255.0)\n",
    "pred = np.argmax(Z, axis=1)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
